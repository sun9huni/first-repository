{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d1977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b959a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0ab714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:40:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-20 13:44:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating                Time\n",
       "31            1    3186       4 2000-12-31 22:00:19\n",
       "22            1    1270       5 2000-12-31 22:00:55\n",
       "27            1    1721       4 2000-12-31 22:00:55\n",
       "37            1    1022       5 2000-12-31 22:00:55\n",
       "24            1    2340       3 2000-12-31 22:01:43\n",
       "...         ...     ...     ...                 ...\n",
       "1000019    6040    2917       4 2001-08-10 14:40:29\n",
       "999988     6040    1921       4 2001-08-10 14:41:04\n",
       "1000172    6040    1784       3 2001-08-10 14:41:04\n",
       "1000167    6040     161       3 2001-08-10 14:41:26\n",
       "1000042    6040    1221       4 2001-08-20 13:44:15\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(os.getenv('HOME')+'/aiffel/yoochoose/data/') \n",
    "train_path = data_path / 'ratings.dat'\n",
    "\n",
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n",
    "    data['Time'] = pd.to_datetime(data['Time'], unit='s')\n",
    "    return data\n",
    "\n",
    "data = load_data(train_path, None)\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf5e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_recursive(data: pd.DataFrame, shortest, least_click) -> pd.DataFrame:\n",
    "    while True:\n",
    "        before_len = len(data)\n",
    "        data = cleanse_short_session(data, shortest)\n",
    "        data = cleanse_unpopular_item(data, least_click)\n",
    "        after_len = len(data)\n",
    "        if before_len == after_len:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_short_session(data: pd.DataFrame, shortest):\n",
    "    session_len = data.groupby('UserId').size()\n",
    "    session_use = session_len[session_len >= shortest].index\n",
    "    data = data[data['UserId'].isin(session_use)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n",
    "    item_popular = data.groupby('ItemId').size()\n",
    "    item_use = item_popular[item_popular >= least_click].index\n",
    "    data = data[data['ItemId'].isin(item_use)]\n",
    "    return data\n",
    "\n",
    "data = cleanse_recursive(data, shortest=2, least_click=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61983f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time'].max()\n",
    "    cutoff_time = final_time - dt.timedelta(n_days)\n",
    "    \n",
    "    train = data[data['Time'] < cutoff_time]\n",
    "    test = data[data['Time'] >= cutoff_time]\n",
    "    return train, test\n",
    "\n",
    "tr, test = split_by_date(data, n_days=1)\n",
    "tr, val = split_by_date(tr, n_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b2f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터의 아이템을 기준으로 인덱스 사전 생성\n",
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    # Train 데이터에 없는 아이템은 -1로 처리\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))\n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8b465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()\n",
    "        self.session_idx = np.arange(self.df['UserId'].nunique())\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        offsets = np.zeros(self.df['UserId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('UserId').size().cumsum()\n",
    "        return offsets\n",
    "\n",
    "class FullSequenceDataLoader:\n",
    "    def __init__(self, dataset: SessionDataset, batch_size=16):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.sessions = self._build_sessions()\n",
    "\n",
    "    def _build_sessions(self):\n",
    "        sessions = []\n",
    "        for start, end in zip(self.dataset.click_offsets[:-1], self.dataset.click_offsets[1:]):\n",
    "            session = self.dataset.df['item_idx'].values[start:end]\n",
    "            if len(session) >= 2:\n",
    "                sessions.append(session)\n",
    "        return sessions\n",
    "\n",
    "    # 'for' 루프를 가능하게 하는 __iter__ 메서드\n",
    "    def __iter__(self):\n",
    "        # 세션 리스트를 배치 사이즈만큼 순회\n",
    "        for i in range(0, len(self.sessions), self.batch_size):\n",
    "            batch = self.sessions[i:i+self.batch_size]\n",
    "            input_batch = []\n",
    "            target_batch = []\n",
    "\n",
    "            for session in batch:\n",
    "                input_batch.append(session[:-1])    # 예: [A, B, C]\n",
    "                target_batch.append(session[-1])    # 예: D\n",
    "            \n",
    "            # 처리된 배치 데이터를 반환\n",
    "            yield input_batch, target_batch\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_dataset = SessionDataset(tr)\n",
    "train_loader = FullSequenceDataLoader(train_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53a7728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, 3416)]      0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 50)                520200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3416)              174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "def create_model(args):\n",
    "    inputs = Input(shape=(None, args.num_items))  # (배치 크기, 시퀀스 길이, 전체 아이템 수)\n",
    "    x = GRU(args.hsz, return_sequences=False)(inputs)\n",
    "    x = Dropout(args.drop_rate)(x)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_sessions = tr['UserId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k\n",
    "\n",
    "args = Args(tr, val, test, batch_size=16, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)\n",
    "\n",
    "model = create_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf567e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 378it [03:37,  1.74it/s, accuracy=0, train_loss=6.49]     \n",
      "Evaluation: 1it [00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 1: 0.0000\n",
      "\t - MRR@20    epoch 1: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 378it [03:37,  1.74it/s, accuracy=0, train_loss=6.13]     \n",
      "Evaluation: 1it [00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 2: 0.0000\n",
      "\t - MRR@20    epoch 2: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 378it [03:37,  1.74it/s, accuracy=0.125, train_loss=5.97] \n",
      "Evaluation: 1it [00:00, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 3: 0.0000\n",
      "\t - MRR@20    epoch 3: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def train_model(model, args):\n",
    "    train_dataset = SessionDataset(args.tr)\n",
    "    train_loader = FullSequenceDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        tr_loader = tqdm(train_loader, desc=f'Train Epoch {epoch}')\n",
    "\n",
    "        for input_seqs, target_items in tr_loader:\n",
    "            # 1. 시퀀스 길이를 맞추기 위해 패딩(padding)을 적용\n",
    "            input_seqs_padded = pad_sequences(input_seqs, padding='pre', maxlen=None)\n",
    "            \n",
    "            # 2. 패딩된 시퀀스를 One-hot-encoding\n",
    "            input_ohe = to_categorical(input_seqs_padded, num_classes=args.num_items)\n",
    "            \n",
    "            # 3. target 아이템을 One-hot-encoding\n",
    "            target_ohe = to_categorical(target_items, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy=result[1])\n",
    "        \n",
    "        # 각 에포크 종료 후 검증 데이터로 성능 평가\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)\n",
    "        print(f\"\\n\\t - Recall@{args.k} epoch {epoch}: {val_recall:.4f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:.4f}\\n\")\n",
    "        \n",
    "def get_metrics(data, model, args, k: int):\n",
    "    dataset = SessionDataset(data)\n",
    "    loader = FullSequenceDataLoader(dataset, batch_size=args.batch_size)\n",
    "\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    for input_seqs, label in tqdm(loader, desc='Evaluation'):\n",
    "        input_seqs_padded = pad_sequences(input_seqs, padding='pre', maxlen=100)\n",
    "        input_ohe = to_categorical(input_seqs_padded, num_classes=args.num_items)  # (B, T, num_items)\n",
    "\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)  # (B, num_items)\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')\n",
    "\n",
    "        for i in range(len(label)):\n",
    "            recall_list.append(recall_k(pred_arg[i], label[i], k))\n",
    "            mrr_list.append(mrr_k(pred_arg[i], label[i], k))\n",
    "\n",
    "    return np.mean(recall_list), np.mean(mrr_list)\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)\n",
    "\n",
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 모델 학습 시작\n",
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2adf382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== EXPERIMENT 1 START ==========\n",
      "Config: {'hsz': 50, 'drop_rate': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, None, 3416)]      0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 50)                520200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3416)              174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 378it [03:39,  1.72it/s, accuracy=0, train_loss=7.47]     \n",
      "Evaluation: 1it [00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 1: 0.0000\n",
      "\t - MRR@20    epoch 1: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 378it [03:37,  1.74it/s, accuracy=0, train_loss=7.04]     \n",
      "Evaluation: 1it [00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 2: 0.0000\n",
      "\t - MRR@20    epoch 2: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 378it [03:37,  1.74it/s, accuracy=0, train_loss=6.77]     \n",
      "Evaluation: 1it [00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 3: 0.0000\n",
      "\t - MRR@20    epoch 3: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 378it [03:37,  1.74it/s, accuracy=0, train_loss=6.36]     \n",
      "Evaluation: 1it [00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 4: 0.0000\n",
      "\t - MRR@20    epoch 4: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 378it [03:37,  1.74it/s, accuracy=0, train_loss=6.16]     \n",
      "Evaluation: 1it [00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 5: 0.0000\n",
      "\t - MRR@20    epoch 5: 0.0000\n",
      "\n",
      "--- Final Test Evaluation for EXPERIMENT 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 1it [00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@20: 0.0000\n",
      "Test MRR@20: 0.0000\n",
      "========== EXPERIMENT 1 END ==========\n",
      "\n",
      "\n",
      "========== EXPERIMENT 2 START ==========\n",
      "Config: {'hsz': 100, 'drop_rate': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None, 3416)]      0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 100)               1055400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3416)              345016    \n",
      "=================================================================\n",
      "Total params: 1,400,416\n",
      "Trainable params: 1,400,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 378it [03:47,  1.66it/s, accuracy=0.125, train_loss=7.32] \n",
      "Evaluation: 1it [00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 1: 0.0000\n",
      "\t - MRR@20    epoch 1: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 378it [03:45,  1.68it/s, accuracy=0, train_loss=6.87]     \n",
      "Evaluation: 1it [00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 2: 0.0000\n",
      "\t - MRR@20    epoch 2: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 378it [03:45,  1.68it/s, accuracy=0, train_loss=11]       \n",
      "Evaluation: 1it [00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 3: 0.0000\n",
      "\t - MRR@20    epoch 3: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 378it [03:45,  1.68it/s, accuracy=0, train_loss=6.79]     \n",
      "Evaluation: 1it [00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 4: 0.0000\n",
      "\t - MRR@20    epoch 4: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 378it [03:44,  1.68it/s, accuracy=0, train_loss=6.69]     \n",
      "Evaluation: 1it [00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 5: 0.0000\n",
      "\t - MRR@20    epoch 5: 0.0000\n",
      "\n",
      "--- Final Test Evaluation for EXPERIMENT 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 1it [00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@20: 0.0000\n",
      "Test MRR@20: 0.0000\n",
      "========== EXPERIMENT 2 END ==========\n",
      "\n",
      "\n",
      "========== EXPERIMENT 3 START ==========\n",
      "Config: {'hsz': 50, 'drop_rate': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None, 3416)]      0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 50)                520200    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3416)              174216    \n",
      "=================================================================\n",
      "Total params: 694,416\n",
      "Trainable params: 694,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 189it [04:23,  1.39s/it, accuracy=0, train_loss=7.47]     \n",
      "Evaluation: 1it [00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 1: 0.0000\n",
      "\t - MRR@20    epoch 1: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 189it [04:20,  1.38s/it, accuracy=0, train_loss=7.27]     \n",
      "Evaluation: 1it [00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 2: 0.0000\n",
      "\t - MRR@20    epoch 2: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 189it [04:20,  1.38s/it, accuracy=0, train_loss=7.2]      \n",
      "Evaluation: 1it [00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 3: 0.0000\n",
      "\t - MRR@20    epoch 3: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 189it [04:20,  1.38s/it, accuracy=0, train_loss=7.08]     \n",
      "Evaluation: 1it [00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 4: 0.0000\n",
      "\t - MRR@20    epoch 4: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 189it [04:20,  1.38s/it, accuracy=0, train_loss=7.01]     \n",
      "Evaluation: 1it [00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Recall@20 epoch 5: 0.0000\n",
      "\t - MRR@20    epoch 5: 0.0000\n",
      "\n",
      "--- Final Test Evaluation for EXPERIMENT 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 1it [00:00, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@20: 0.0000\n",
      "Test MRR@20: 0.0000\n",
      "========== EXPERIMENT 3 END ==========\n",
      "\n",
      "\n",
      "========== FINAL EXPERIMENT SUMMARY ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsz</th>\n",
       "      <th>drop_rate</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>recall@20</th>\n",
       "      <th>mrr@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hsz  drop_rate      lr  batch_size  recall@20  mrr@20\n",
       "0   50        0.1  0.0010          16        0.0     0.0\n",
       "1  100        0.1  0.0010          16        0.0     0.0\n",
       "2   50        0.1  0.0005          32        0.0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 실험할 하이퍼파라미터 조합을 리스트로 정의\n",
    "experiment_configs = [\n",
    "    {'hsz': 50, 'drop_rate': 0.1, 'lr': 0.001, 'batch_size': 16},  # 베이스라인 실험\n",
    "    {'hsz': 100, 'drop_rate': 0.1, 'lr': 0.001, 'batch_size': 16}, # 모델 복잡도 증가 (hsz)\n",
    "    {'hsz': 50, 'drop_rate': 0.1, 'lr': 0.0005, 'batch_size': 32}, # 학습률 감소\n",
    "]\n",
    "\n",
    "# 각 실험의 최종 결과를 저장할 리스트\n",
    "results = []\n",
    "\n",
    "# 2. for 문을 통해 실험 자동화\n",
    "for i, config in enumerate(experiment_configs):\n",
    "    print(f\"========== EXPERIMENT {i+1} START ==========\")\n",
    "    print(f\"Config: {config}\")\n",
    "\n",
    "    # 현재 설정에 맞는 Args 인스턴스 생성\n",
    "    args = Args(tr, val, test,\n",
    "                batch_size=config['batch_size'],\n",
    "                hsz=config['hsz'],\n",
    "                drop_rate=config['drop_rate'],\n",
    "                lr=config['lr'],\n",
    "                epochs=5,  # 실험을 위해 에포크는 5회로 고정\n",
    "                k=20)\n",
    "\n",
    "    # 매 실험마다 새로운 모델 생성\n",
    "    model = create_model(args)\n",
    "\n",
    "    # 모델 학습\n",
    "    train_model(model, args)\n",
    "\n",
    "    # 학습 완료 후 테스트셋으로 최종 평가\n",
    "    print(f\"--- Final Test Evaluation for EXPERIMENT {i+1} ---\")\n",
    "    test_recall, test_mrr = get_metrics(args.test, model, args, args.k)\n",
    "    print(f\"Test Recall@20: {test_recall:.4f}\")\n",
    "    print(f\"Test MRR@20: {test_mrr:.4f}\")\n",
    "\n",
    "    # 결과 저장\n",
    "    config_result = config.copy()\n",
    "    config_result['recall@20'] = test_recall\n",
    "    config_result['mrr@20'] = test_mrr\n",
    "    results.append(config_result)\n",
    "    \n",
    "    print(f\"========== EXPERIMENT {i+1} END ==========\\n\\n\")\n",
    "\n",
    "\n",
    "# 3. 전체 실험 결과 비교\n",
    "print(\"========== FINAL EXPERIMENT SUMMARY ==========\")\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
